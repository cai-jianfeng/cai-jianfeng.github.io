---
title: 'The Basic Knowledge of Expectation Maximization Algorithm'
data: 23-12-02
permalink: '/posts/2023/12/blog-em_algorithm'
tags:
  - 机器学习基础知识
---

<p style="text-align:justify; text-justify:inter-ideograph;">这篇博客参考了<a href="https://blog.csdn.net/qq_36583400/article/details/127047093" target="_blank">
俗理解EM算法</a>，详细推导了 Expectation Maximization (EM) 算法。</p>

<p style="text-align:justify; text-justify:inter-ideograph;">EM 算法，即期望最大化算法，其目的是求解带有隐含变量 $z$ 的最大似然值的问题。
与一般的最大似然问题不同，后者一般只包含未知分布参数 $\theta$。
举个例子，假设一个学校的男生和女生的身高分布是一个高斯分布：$\mathcal{N}(\mu, \sigma^2)$，
其中的 $\mu_1, \sigma_1^2$ 表示男生身高分布的均值和方差；$\mu_2, \sigma_2^2$ 表示女生身高分布的均值和方差。
假设我们采样了 $50$ 个男生的身高分别为 $\{x_1^m,...,x_{50}^m\}$，$50$ 个女生的身高分别为 $\{x_1^w,...,x_{50}^w\}$。
在这种情况下求解对应的 $\mu_1,\sigma_1^2,\mu_2,\sigma_2^2 \rightarrow \theta$ 就是属于一般的最大似然问题。
假设我们采样了 $100$ 个同学的身高分别为 $\{x_1^z,...,x_{100}^z\}$，但是并不知道每个同学的性别 $z, z\in\{m,w\}$。
此时性别变量 $z$ 就属于隐含变量，而在这种情况下求解对应的 $\mu_1,\sigma_1^2,\mu_2,\sigma_2^2 \rightarrow \theta$ 就是属于带有隐含变量 $z$ 的最大似然问题。</p>

